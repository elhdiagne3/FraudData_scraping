{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bffd2f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diagne080894\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2023-12-14 16:32:09.230 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# In[2]:\n",
    "import time  # to simulate a real time data, time loop\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import numpy as np  # np mean, np random\n",
    "import pandas as pd  # read csv, df manipulation\n",
    "import plotly.express as px  # interactive charts\n",
    "import streamlit as st  \n",
    "import streamlit_authenticator as stauth\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import ImageColorGenerator\n",
    "from wordcloud import WordCloud\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.models import ColumnDataSource, Div, Slider, CustomJS\n",
    "from bokeh.layouts import Column\n",
    "#output_notebook() #create default state to generate the output\n",
    "from bokeh.models import Slider, Div, CustomJS, Column\n",
    "from bokeh.layouts import layout\n",
    "from bokeh.io import show\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import  Counter\n",
    "nltk.download('stopwords')\n",
    "#st.markdown(\"# Facebook üéà\")\n",
    "#st.sidebar.markdown(\"# Facebook üéà\")\n",
    "st.set_page_config(\n",
    "        page_title=\"OML Fraude Data Web Scraping\",\n",
    "        page_icon=\"ü§≥\",\n",
    "        layout=\"wide\"\n",
    "    )\n",
    "from credentials import user_credentials  # Import user_credentials from the external file\n",
    "\n",
    "def login():\n",
    "    st.title(\"Login Page\")\n",
    "\n",
    "    username = st.text_input(\"Username\")\n",
    "    password = st.text_input(\"Password\", type='password')\n",
    "\n",
    "    if st.button(\"Login\"):\n",
    "        if username == user_credentials['username'] and password == user_credentials['password']:\n",
    "            st.success(\"Login successful!\")\n",
    "            return True\n",
    "        else:\n",
    "            st.error(\"Invalid username or password.\")\n",
    "            return False\n",
    "\n",
    "def main_page():\n",
    "    \n",
    "    col1, col2, col3 = st.columns(3)\n",
    "    image = Image.open(\"t√©l√©chargement.png\")\n",
    "    with col1 : \n",
    "        st.markdown(\n",
    "        \"\"\"\n",
    "        <style>\n",
    "            button[title^=Exit]+div [data-testid=stImage]{\n",
    "                text-align: center;\n",
    "                display: block;\n",
    "                margin-left: auto;\n",
    "                margin-right: auto;\n",
    "                width: 50%;\n",
    "                body {\n",
    "                    color: Ivory;\n",
    "                } </style>\n",
    "        \"\"\", unsafe_allow_html=True)\n",
    "        st.image(image, width=75)\n",
    "    ###################### dashboard title\n",
    "    with col2 : \n",
    "        st.markdown(\n",
    "            f\"\"\"\n",
    "            <h1 style='text-align: center; font-size: 25px; font-family: Arial; font-weight: bold;'>Data Fraud OML: <br> Web/Social Media scraping</h1>\n",
    "            \"\"\", \n",
    "           unsafe_allow_html=True\n",
    "        )\n",
    "    st.markdown(\n",
    "    \"\"\"\n",
    "    <style>\n",
    "    /* CSS to change sidebar font color */\n",
    "    .sidebar .sidebar-content {\n",
    "        color: purple; /* Change 'purple' to the color you desire */\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\",\n",
    "    unsafe_allow_html=True\n",
    ")\n",
    "    \n",
    "    st.sidebar.success(\"\")\n",
    "\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "        <p style='color: Black and Neon Blue; font-size:20px;font-family: Arial; font-weight: bold'><strong> üëâ Web/Fraud Data OML Social media scraping.</strong></p>\n",
    "\n",
    "       <p style='color: Black and Neon Blue; font-size:18px; font-weight: bold'> Ces r√©sultats nous permettent d'avoir une id√©e d'une par sur le niveau d'attraction des internautes sur la fraude data et d'autre part, de comprendre, les techniques & outils utilis√©s pour baypasser nos syst√®me de facturation.\n",
    "       <br> Cela pourrait aider √† prendre des d√©cision afin de r√©duire le volume trafic data frauduleux.</p>\n",
    "        <p style='color: darq green; font-size:20px;font-family: Arial; font-weight: bold'><strong> üëâ Source des donn√©es :</strong> </p> \n",
    "        <h2 style='color: Black and Neon Blue; font-size:15px;font-weight: bold' '>Google, Facebook, Instagram, Twitter, Telegram.</h2> </p>\n",
    "        <p style='color: Black and Neon Blue; font-size:18px; font-weight: bold'> Pour chacune des sources, il existe des packages Python ou APIs d√©di√©s pour le scraping.\n",
    "        Les donn√©es extraites sont compil√©es, n√©toy√©es et analys√©es (√† l'anonymat) √† des fin de visualisation.</p>\n",
    "        <p style='color: darq green; font-size:20px;font-family: Arial; font-weight: bold'><strong>üëà Select a page from the sidebar ! </strong> </p>\n",
    "    \"\"\", unsafe_allow_html=True\n",
    "    )\n",
    "\n",
    "\n",
    "def page2():\n",
    "    st.markdown(\"<style> footer {visibility: hidden;} </style>\", unsafe_allow_html=True)\n",
    "\n",
    "    # read csv from a github repo\n",
    "    dataset_url = \"https://raw.githubusercontent.com/elhdiagne3/FraudData_scraping/master/goups_post.csv\"\n",
    "    dataset_url2 = \"https://raw.githubusercontent.com/elhdiagne3/FraudData_scraping/master/group.csv\"\n",
    "    dataset_url3 = \"https://raw.githubusercontent.com/elhdiagne3/FraudData_scraping/master/all_link.csv\"\n",
    "    # read csv from a URL\n",
    "    @st.cache_data(ttl=60, persist=\"disk\", show_spinner=False)\n",
    "    def get_data() -> pd.DataFrame:\n",
    "        return pd.read_csv(dataset_url, sep=';', encoding='utf-8', encoding_errors= 'ignore'), pd.read_csv(dataset_url2, sep=';', encoding='utf-8', encoding_errors= 'ignore'), pd.read_csv(dataset_url3, sep=',', encoding='utf-8', encoding_errors= 'ignore')\n",
    "    df, df1, df2 = get_data()\n",
    "    df.drop_duplicates('post_id', inplace = True)\n",
    "    df = df[df.post_id!='613.339.656.815.365']\n",
    "    df1.drop_duplicates('id', inplace = True)\n",
    "    #df = data\n",
    "    #def show() : \n",
    "    st.sidebar.header(\"\")\n",
    "    left_co, cent_co,last_co = st.columns(3)\n",
    "    default_year = [2021,2022,2023]\n",
    "    with cent_co:\n",
    "        st.markdown(\n",
    "        \"\"\"\n",
    "        <style>\n",
    "            .multiselect label, .multiselect select {\n",
    "                width: 100%;\n",
    "                padding: 8px;\n",
    "                border: 1px solid #ccc;\n",
    "                border-radius: 4px;\n",
    "                font-size: 15px;\n",
    "                background-color: #f7f7f7;\n",
    "                color: #333;\n",
    "            }\n",
    "        </style>\n",
    "        \"\"\",\n",
    "        unsafe_allow_html=True\n",
    "        )\n",
    "        source_filter = st.multiselect(\"Select the year of posts\", pd.unique(df[\"year\"]), default=default_year)\n",
    "        #source_filter_ = st.multiselect(\"Select the post_type of posts\", pd.unique(df[\"post_type\"]), default=default_year)\n",
    "        placeholder = st.empty()\n",
    "        df = df[df.post_type == 'fraud_post']\n",
    "        df = df[df[\"year\"].isin(source_filter)]\n",
    "        dfs = df['post_id'].groupby(df['year_mm']).count().reset_index()\n",
    "        dfs['nb_post'] = dfs['post_id']\n",
    "        df_ = df['likes'].groupby(df['year_mm']).sum().reset_index().sort_values('year_mm')\n",
    "        df__ = df['comments'].groupby(df['year_mm']).sum().reset_index().sort_values('year_mm')\n",
    "    # Fonction pour formater les grands nombres en K ou M\n",
    "    def format_number(num):\n",
    "        if num >= 1000000:  # Si le nombre est sup√©rieur √† 1 million\n",
    "            return f\"{num / 1_000_000:.1f} M\"  # Convertir en millions et formater avec une d√©cimale\n",
    "        elif num >= 10000:  # Si le nombre est sup√©rieur √† 1 mille\n",
    "            return f\"{num / 1000:.1f} K\"  # Convertir en milliers et formater avec une d√©cimale\n",
    "        else:\n",
    "            return str(num)  # Garder le nombre inchang√© s'il est plus petit\n",
    "\n",
    "    for seconds in range(200):\n",
    "        # creating KPIs\n",
    "        nb_group = df1.id.count()\n",
    "        nb_member = df1['members'].sum()\n",
    "        nb_post = df[\"post_id\"].count()\n",
    "        nb_likes = int(df.likes.sum())\n",
    "        nb_comments = df.comments.sum()\n",
    "        nb_shares = df.shares.sum()\n",
    "    with st.container():\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            kpi1, kpi2, kpi3, kpi4, kpi5, kpi6 = st.columns(6)\n",
    "\n",
    "                    # Display the embellished label and kpi1.metric in col1\n",
    "            with col1:\n",
    "                with kpi1 : \n",
    "                    st.markdown(\n",
    "                        \"<div style='text-align: center; font-size: 18px; font-family: Arial; font-weight: bold; color: black;'>\"\n",
    "                        \"nb group üë™</div>\",\n",
    "                        unsafe_allow_html=True\n",
    "                    )\n",
    "\n",
    "                    st.markdown(\n",
    "                        \"<div style='text-align: center; font-size: 35px; font-family: Arial; font-weight: bold; color: green;'>\"\n",
    "                        f\"{format_number(nb_group)}</div>\",\n",
    "                        unsafe_allow_html=True\n",
    "                    )\n",
    "                with kpi2 :\n",
    "                    st.markdown(\n",
    "                        \"<div style='text-align: center; font-size: 18px; font-family: Arial; font-weight: bold; color: black;'>\"\n",
    "                        \"nb members üôå</div>\",\n",
    "                        unsafe_allow_html=True\n",
    "                    )\n",
    "\n",
    "                    st.markdown(\n",
    "                        \"<div style='text-align: center; font-size: 35px; font-family: Arial; font-weight: bold; color: green;'>\"\n",
    "                        f\"{format_number(nb_member)}</div>\",\n",
    "                        unsafe_allow_html=True\n",
    "                    )\n",
    "            with col2:\n",
    "                with kpi3 :                \n",
    "                    st.markdown(\n",
    "                        \"<div style='text-align: center; font-size: 18px; font-family: Arial; font-weight: bold; color: black;'>\"\n",
    "                        \"nb posts ‚è≥</div>\",\n",
    "                        unsafe_allow_html=True\n",
    "                    )\n",
    "\n",
    "                    st.markdown(\n",
    "                        \"<div style='text-align: center; font-size: 35px; font-family: Arial; font-weight: bold; color: green;'>\"\n",
    "                        f\"{format_number(nb_post)}</div>\",\n",
    "                        unsafe_allow_html=True\n",
    "                    )\n",
    "                with kpi4:\n",
    "                    st.markdown(\n",
    "                            \"<div style='text-align: center; font-size: 18px; font-family: Arial; font-weight: bold; color: black;'>\"\n",
    "                            \"nb likes üëç</div>\",\n",
    "                            unsafe_allow_html=True\n",
    "                        )\n",
    "                    st.markdown(\n",
    "                            \"<div style='text-align: center; font-size: 35px; font-family: Arial; font-weight: bold; color: green;'>\"\n",
    "                            f\"{format_number(nb_likes)}</div>\",\n",
    "                            unsafe_allow_html=True\n",
    "                        )\n",
    "\n",
    "            with col3:\n",
    "                with kpi5 : \n",
    "                    st.markdown(\n",
    "                            \"<div style='text-align: center; font-size: 18px; font-family: Arial; font-weight: bold; color: black;'>\"\n",
    "                            \"nb comments ‚úçÔ∏è</div>\",\n",
    "                            unsafe_allow_html=True\n",
    "                        )\n",
    "                    st.markdown(\n",
    "                            \"<div style='text-align: center; font-size: 35px; font-family: Arial; font-weight: bold; color: green;'>\"\n",
    "                            f\"{format_number(nb_comments)}</div>\",\n",
    "                            unsafe_allow_html=True\n",
    "                        )\n",
    "\n",
    "                with kpi6 : \n",
    "                    st.markdown(\n",
    "                        \"<div style='text-align: center; font-size: 18px; font-family: Arial; font-weight: bold; color: black;'>\"\n",
    "                        \"nb shares üëã</div>\",\n",
    "                        unsafe_allow_html=True\n",
    "                    )\n",
    "                    st.markdown(\n",
    "                        \"<div style='text-align: center; font-size: 35px; font-family: Arial; font-weight: bold; color: green;'>\"\n",
    "                        f\"{format_number(nb_shares)}</div>\",\n",
    "                        unsafe_allow_html=True\n",
    "                    )\n",
    "            fig_col1, fig_col2 = st.columns(2)\n",
    "            with fig_col1:\n",
    "                fig = px.line(dfs, x = 'year_mm', y = 'nb_post',markers = True,  line_shape=\"spline\", render_mode=\"svg\", \n",
    "                width=600, height=400)\n",
    "                fig.update_layout(title_text='üìà : Evolution du nombre de posts par mois', title_x=0.4)\n",
    "                st.write(fig)\n",
    "            with fig_col2:\n",
    "                fig = px.line(width=600, height=400,markers = True, render_mode=\"svg\")\n",
    "                fig.update_layout(title_text='üìà : Evolution du nombre de likes & de comments par mois', title_x=0.1)\n",
    "                fig.add_scatter(x=df_['year_mm'], y=df_['likes'], mode='lines', line_shape=\"spline\",marker= dict(color = 'blue'), name='nb_likes')\n",
    "                fig.add_scatter(x=df__['year_mm'], y=df__['comments'], mode='lines', line_shape=\"spline\", marker= dict(color = 'green'), name='nb_Comments')\n",
    "                st.plotly_chart(fig) \n",
    "            col1, col2 = st.columns(2)\n",
    "            with col1 :\n",
    "                df1.sort_values('members',ascending=False, inplace=True)\n",
    "                df1['name'] = df1.name.str.lower()\n",
    "                df1_ = df1[~((df1.name.str.contains('ci')) | (df1.name.str.contains('mtn')) | (df1.name.str.contains('rdc')) | (df1.name.str.contains('camero')))].head(15)\n",
    "                df1_.sort_values('members', ascending = False, inplace = True)\n",
    "                fig = px.bar(df1_, x = 'name', y = 'members', \n",
    "                width=600, height=800)\n",
    "                fig.update_layout(\n",
    "                xaxis_title='Name groups',\n",
    "                yaxis_title='Number of members',\n",
    "                plot_bgcolor='white',  # Transparent plot background\n",
    "                paper_bgcolor='rgb(255,255,255)',  # White background\n",
    "                font=dict(family='Arial', size=12, color='black'),  # Font style\n",
    "                margin=dict(l=50, r=50, t=50, b=50),  # Setting margins\n",
    "                xaxis=dict(tickangle=45),  # Rotating x-axis labels\n",
    "                yaxis=dict(tickformat=',d'),  # Adding comma to y-axis labels for thousands separator, \n",
    "                title = 'üìä Graph III : Nb_members : Top 10 group',\n",
    "                title_x = 0.4\n",
    "            )\n",
    "                st.write(fig)        \n",
    "            with col2 : \n",
    "                df['text'].fillna(\".\", inplace =True)\n",
    "                df['text'] = df.text.str.lower()\n",
    "                df = df[~((df.text.str.contains('ivoire')) | (df.text.str.contains('faso')) | (df.text.str.contains('camero')) | (df.text.str.contains('benin')) |(df.text.str.contains('mtn')) )]\n",
    "                text = df.text.tolist()\n",
    "                text_ =' '.join(text)\n",
    "                text_.encode('utf-16').decode('utf-16')\n",
    "                #Instantiate the wordcloud using color_func argument\n",
    "                cloud = WordCloud(font_path= 'font.ttf', width=600, height=550,colormap= 'rainbow',background_color='black',min_word_length =4).generate(text_)\n",
    "                #Plot the wordcloud\n",
    "                #plt.figure(figsize=(15,10))\n",
    "                #plt.text(0.5, 1.15, f\"Word Cloud Fraud Data Post\", size=24, ha='center', transform=plt.gca().transAxes\n",
    "                st.markdown(\"\"\"<p text-align: centerstyle='color: Black and Neon Blue; font-size:15px;font-family: Arial; font-weight: bold'>üìö WordCloud Data Fraud 2021-2023. </p>\"\"\", unsafe_allow_html = True) \n",
    "                st.image(cloud.to_array(), width=0, use_column_width=True,caption = \"\" )\n",
    "            col1, col2 = st.columns(2)\n",
    "            with st.container() :\n",
    "                with col1 : \n",
    "                    df_tlg= df2[df2.link.str.contains('https://t.me')]\n",
    "                    df_tlg.sort_values('count',ascending=False, inplace=True)\n",
    "                    df_tlg = df_tlg.head(10)\n",
    "                    df_tlg = df_tlg[['link', 'count']]\n",
    "                    st.write('TOP 10 Telegram Link : Number of posts') \n",
    "                    st.table(df_tlg)\n",
    "                with col2 : \n",
    "                    df_wts= df2[df2.link.str.contains('https://chat.whatsapp')]\n",
    "                    df_wts.sort_values('count',ascending=False, inplace=True)\n",
    "                    df_wts = df_wts.head(10)\n",
    "                    df_wts = df_wts[['link', 'count']]\n",
    "                    st.write('TOP 10 WhatsApp Link : Number of posts') \n",
    "                    st.table(df_wts)\n",
    "                    ######################  Interactive dashboard (Bokeh) #########\n",
    "            with st.container() :\n",
    "                df['text2'] = df.text.str.lower()\n",
    "                data_ = df[(df.text2.str.contains('internet')) & (df.year_mm.str.contains('2023-10', '2023-11')) ]\n",
    "                data_ = data_.sort_values('comments', ascending=False).head(25)\n",
    "                data_ = data_[['post_id', 'text']]\n",
    "                cds = ColumnDataSource(data_)\n",
    "\n",
    "                from bokeh.models import Slider, Div, CustomJS, Column\n",
    "                from bokeh.layouts import layout\n",
    "                from bokeh.io import show\n",
    "\n",
    "                # Create slider, div_text, and div_label\n",
    "                slider = Slider(title='Post_id', start=0, end=data_.shape[0]-1, value=0)\n",
    "                div_text = Div(text=\"Facebook post Text:\", width=660, height=100)\n",
    "                div_label = Div(text=\"post Label:\", width=600, height=100)\n",
    "\n",
    "                initial_text = cds.data['text'][1]\n",
    "                initial_label = cds.data['post_id'][1]\n",
    "                div_text.text = 'post Text:<br>' + initial_text\n",
    "                div_label.text = 'post ID:<br>' + str(initial_label)\n",
    "\n",
    "                # Define a callback function for the slider\n",
    "                slider_callback = CustomJS(args=dict(slider=slider, div_text=div_text, div_label=div_label, cds=cds), code='''\n",
    "                    var post_text = cds.data['text'][slider.value];\n",
    "                    var post_label = cds.data['post_id'][slider.value];\n",
    "                    div_text.text = 'Post Text:<br>' + post_text;\n",
    "                    div_label.text = 'Post Label:<br>' + post_label;\n",
    "                ''') \n",
    "\n",
    "                # Attach the callback to the 'value' property of the slider\n",
    "                slider.js_on_change('value', slider_callback)\n",
    "\n",
    "                # Arrange the components in a layout\n",
    "                layout = layout([[slider], [div_text, div_label]])\n",
    "                # Show the layout\n",
    "                st.bokeh_chart(layout)\n",
    "\n",
    "def page3():\n",
    "    st.markdown(\"<style> footer {visibility: hidden;} </style>\", unsafe_allow_html=True)\n",
    "    st.sidebar.header('')\n",
    "    dataset_url = \"https://raw.githubusercontent.com/elhdiagne3/FraudData_scraping/master/goog_process.csv\"\n",
    "    dataset_url2 = \"https://raw.githubusercontent.com/elhdiagne3/FraudData_scraping/master/google_all.csv\"\n",
    "    # read csv from a URL\n",
    "    @st.cache_data(ttl=60, persist=\"disk\", show_spinner=False)\n",
    "    def get_data() -> pd.DataFrame:\n",
    "        return pd.read_csv(dataset_url, sep=',', encoding='utf-8', encoding_errors= 'ignore'), pd.read_csv(dataset_url2, sep=',', encoding='utf-8', encoding_errors= 'ignore')\n",
    "    data, df = get_data()\n",
    "    df = df[~df.Link.str.contains('orangemali.com')]\n",
    "    nb_pages = df.drop_duplicates().shape[0]\n",
    "    data = data[data.word != '...'].head(15)\n",
    "    with st.container() : \n",
    "        col1, col2, col3 = st.columns(3)\n",
    "        with col2:\n",
    "            st.markdown(\n",
    "                \"<div style='text-align: center; font-size: 18px; font-family: Arial; font-weight: bold; color: black;'>\"\n",
    "                \"nb pages üë™</div>\",\n",
    "                unsafe_allow_html=True\n",
    "            )\n",
    "            st.markdown(\n",
    "                \"<div style='text-align: center; font-size: 35px; font-family: Arial; font-weight: bold; color: green;'>\"\n",
    "                f\"{nb_pages}</div>\",\n",
    "                unsafe_allow_html=True\n",
    "            )\n",
    "        col1, col2 = st.columns(2)\n",
    "        with col1:\n",
    "            fig = px.bar(data, x = 'word', y = 'count', \n",
    "            width=600, height=600 )\n",
    "            fig.update_layout(\n",
    "            xaxis_title='words',\n",
    "            yaxis_title='Frequency of word',\n",
    "            plot_bgcolor='white',  # Transparent plot background\n",
    "            paper_bgcolor='rgb(250,250,250)',  # White background\n",
    "            font=dict(family='Arial', size=12, color='black'),  # Font style\n",
    "            margin=dict(l=50, r=50, t=50, b=50),  # Setting margins\n",
    "            xaxis=dict(tickangle=45),  # Rotating x-axis labels\n",
    "            yaxis=dict(tickformat=',d'),  # Adding comma to y-axis labels for thousands separator, \n",
    "            title = 'üìä TOP 15 of words',\n",
    "            title_x = 0.4\n",
    "            ) \n",
    "            st.write(fig)\n",
    "        with col2 :\n",
    "            def plot_top_ngrams_barchart(text, n=3):\n",
    "                stop=set(stopwords.words('french'))\n",
    "                new= text.str.split()\n",
    "                new=new.values.tolist()\n",
    "                corpus=[word for i in new for word in i]\n",
    "\n",
    "                def _get_top_ngram(corpus, n=None):\n",
    "                    vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)\n",
    "                    bag_of_words = vec.transform(corpus)\n",
    "                    sum_words = bag_of_words.sum(axis=0) \n",
    "                    words_freq = [(word, sum_words[0, idx]) \n",
    "                                  for word, idx in vec.vocabulary_.items()]\n",
    "                    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "                    return words_freq[:15]\n",
    "\n",
    "                top_n_bigrams=_get_top_ngram(text,n)[:15]\n",
    "                x,y=map(list,zip(*top_n_bigrams))\n",
    "                plt.figure(figsize=(6, 8))\n",
    "                plot = sns.barplot(x=y, y=x)  # Adjust palette as needed\n",
    "                plot.set_title(f\"Top {n}-Grams Barplot\")\n",
    "            st.set_option('deprecation.showPyplotGlobalUse', False)\n",
    "            plt.title(f\"Top {3}-Grams Barplot\")\n",
    "            plot_top_ngrams_barchart(df['Title'],3)\n",
    "            st.pyplot()\n",
    "        with st.container() : \n",
    "            st.markdown(\"\"\"<style>\n",
    "        .sidebar .sidebar-content {\n",
    "            font-family: 'Arial', sans-serif;\n",
    "            font-size: 25px;\n",
    "            text-align : center;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "    </style>\"\"\", unsafe_allow_html=True)\n",
    "            st.title('Table google page')\n",
    "            st.write(df.sample(30))\n",
    "def page4():\n",
    "    st.markdown(\"<style> footer {visibility: hidden;} </style>\", unsafe_allow_html=True)\n",
    "    st.sidebar.header('')\n",
    "def page5():\n",
    "    st.markdown(\"\"\"<style>\n",
    "        .sidebar .sidebar-content {\n",
    "            font-family: 'Arial', sans-serif;\n",
    "            font-size: 25px;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "    </style>\"\"\", unsafe_allow_html=True)\n",
    "    st.sidebar.header('')\n",
    "        # read csv from a github repo\n",
    "    dataset_url = \"https://raw.githubusercontent.com/elhdiagne3/FraudData_scraping/main/goups_post.csv\"\n",
    "    dataset_url2 = \"https://raw.githubusercontent.com/elhdiagne3/FraudData_scraping/main/group.csv\"\n",
    "    # read csv from a URL\n",
    "    @st.cache_data(ttl=60, persist=\"disk\", show_spinner=False)\n",
    "    \n",
    "    def get_data() -> pd.DataFrame:\n",
    "        return pd.read_csv(dataset_url, sep=',', encoding='utf-8', encoding_errors= 'ignore'), pd.read_csv(dataset_url2, sep=',', encoding='utf-8', encoding_errors= 'ignore')\n",
    "    df, df1 = get_data()\n",
    "    def get_table_download_link_csv(df):\n",
    "        csv = df.to_csv(index=False, encoding = 'utf_8')\n",
    "        b64 = base64.b64encode(csv.encode()).decode()  # Encoding the CSV file\n",
    "        href = f'<a href=\"data:file/csv;base64,{b64}\" download=\"data.csv\">Download Table (CSV) File</a>'\n",
    "        return href\n",
    "    st.title('DataTable with Download Option to CSV')\n",
    "    # Display DataTable\n",
    "    df = df.drop('header', axis = 1)\n",
    "    st.dataframe(df[df.post_type == 'fraud_post'].sample(15))\n",
    "    st.dataframe(df1.sample(15))\n",
    "    # Option to download the DataFrame as a CSV file \n",
    "    st.markdown(f\"\"\"<p style='text-align: center; color: Black and Neon Blue; font-size:15px;font-family: Arial; font-weight: bold >{get_table_download_link_csv(df)}\"\"\", unsafe_allow_html=True)\n",
    "        \n",
    "    time.sleep(1)\n",
    "page_names_to_funcs = {\n",
    "    \"Home\": main_page,\n",
    "    \"Google\": page3,\n",
    "    \"Facebook\": page2,\n",
    "    \"Kibaru\": page4,\n",
    "    \"DataTable\": page5,\n",
    "}\n",
    "# Streamlit sidebar with icons, font, and bold text\n",
    "st.markdown(\n",
    "    \"\"\"\n",
    "    <style>\n",
    "        .sidebar .sidebar-content {\n",
    "            font-family: 'Arial', sans-serif;\n",
    "            font-size: 25px;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "    </style>\n",
    "    \"\"\",\n",
    "    unsafe_allow_html=True,\n",
    ")\n",
    "\n",
    "st.sidebar.title(\"Navigation\")\n",
    "\n",
    "# Customize the appearance of the radio buttons with icons\n",
    "selected_page = st.sidebar.radio(\n",
    "    \"\",\n",
    "    list(page_names_to_funcs.keys()),\n",
    "    format_func=lambda page: f\"{page} {'üè†' if page == 'Home' else 'üîç' if page == 'Google' else '' if page == 'Facebook' else 'üìä' if page == 'DataTable' else ''}\",\n",
    ")\n",
    "\n",
    "# Call the selected page function\n",
    "page_names_to_funcs[selected_page]()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
